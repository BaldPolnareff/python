{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using my base anaconda environment for this notebook, as opposed to the python runtimes I usually use for my other notebooks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy vs Torch\n",
    "\n",
    "Numpy **arrays** and PyTorch **tensors** are similar in many ways. They both are n-dimensional arrays, and they both support a large number of operations. However, there are some important differences between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(0, 1, 5)\n",
    "t = torch.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.25, 0.5 , 0.75, 1.  ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can be resized very similarly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(48).reshape(3, 4, 4)\n",
    "t = torch.arange(48).reshape(3, 4, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have the same broadcasting rules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Broadcasting Rules\n",
    "\n",
    "**NumPy** compares the shape of the two arrays element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when \n",
    "\n",
    "1. they are equal, or\n",
    "2. one of them is 1\n",
    "\n",
    "**Example**: The following arrays are compatible for broadcasting:\n",
    "\n",
    "    Shape1: (1, 6, 4, 1, 7, 2)\n",
    "    Shape2: (5, 6, 1, 3, 1, 2)\n",
    "\n",
    "Notice the numbers in parentheses are not actual elements of the array, but rather the shape of the array (they're both 6-dimensional arrays). The trailing dimensions are compatible because they are equal. The next two dimensions are compatible because one of them is 1. \n",
    "Going forward and checking element-wise, the two arrays are compatible for broadcasting.\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((6, 5))\n",
    "b = np.arange(5).reshape((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're compatible! The trailing dimensions are equal, and the next two dimensions are compatible because one of them is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b$ has been broadcasted to match the shape of $a$, notice how it has been added elementwise and for each of the 5 rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these examples work the same way using PyTorch tensors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Scaling each of the color channels of an image by a different amount \n",
    "\n",
    "        Image  (3D array): 256 x 256 x 3\n",
    "        Scale  (1D array):             3\n",
    "        Result (3D array): 256 x 256 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = torch.randn((256, 256, 3))\n",
    "Scale = torch.tensor([0.5, 1.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = Image * Scale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel has its own RGB value and the scale array is broadcasted by automatically \"filling\" the missing dimensions with 1, which is compatible with the 3D array, as we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4851,  0.6219,  1.1986],\n",
       "         [-0.5104, -0.1032, -1.1994],\n",
       "         [-0.2464,  0.9703,  0.2011],\n",
       "         ...,\n",
       "         [ 0.0038, -0.6432,  0.5227],\n",
       "         [ 0.2252, -1.7203,  0.7954],\n",
       "         [-1.4113, -1.5692,  0.3791]],\n",
       "\n",
       "        [[-0.1975, -2.2298,  0.0923],\n",
       "         [-0.2060,  1.7708, -0.7949],\n",
       "         [-0.1571, -2.8495, -1.2338],\n",
       "         ...,\n",
       "         [-0.1112,  0.9085, -0.2579],\n",
       "         [-0.1972,  0.7657, -2.3204],\n",
       "         [-0.3097,  3.6715,  0.0459]],\n",
       "\n",
       "        [[ 0.4238,  2.5619,  1.1865],\n",
       "         [-0.1382, -0.4225, -0.1328],\n",
       "         [-0.2797, -0.6732,  0.3435],\n",
       "         ...,\n",
       "         [ 0.1257, -2.3191,  1.0249],\n",
       "         [-0.2588, -0.7808,  0.1031],\n",
       "         [-0.3322,  0.2506,  1.8672]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5494, -2.5491,  0.0916],\n",
       "         [ 0.0252, -0.0083, -0.7250],\n",
       "         [ 0.0184, -1.0566, -1.0034],\n",
       "         ...,\n",
       "         [ 0.2031,  0.8488, -1.8105],\n",
       "         [ 0.4318, -0.8357,  0.8961],\n",
       "         [-0.3683, -0.8883,  1.5579]],\n",
       "\n",
       "        [[ 0.7168, -0.7356,  0.0319],\n",
       "         [ 0.1881, -0.2245, -0.9814],\n",
       "         [ 0.1015,  1.2723, -1.0204],\n",
       "         ...,\n",
       "         [ 0.4998,  1.9029,  0.7192],\n",
       "         [-0.0375, -0.0233, -0.8943],\n",
       "         [ 0.1120, -1.3330, -0.4492]],\n",
       "\n",
       "        [[-0.3810, -0.0664, -1.2140],\n",
       "         [ 0.9256,  0.5871,  0.0358],\n",
       "         [ 0.8679, -1.4070, -0.7121],\n",
       "         ...,\n",
       "         [ 0.0895,  2.5854, -2.1417],\n",
       "         [-0.2851,  2.0311,  0.1345],\n",
       "         [-0.9559,  0.2729, -0.9574]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2c9d14e2283efc71dd845cb84a05c6dc0b4f1a825c12450a6974e74c8800d0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
